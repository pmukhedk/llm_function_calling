{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# With Tool Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import yaml\n",
    "import json\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(\n",
    "    base_url = 'http://localhost:11434/v1',\n",
    "    api_key='ollama',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "weatherTool = {\n",
    "    \"name\": \"get_current_weather\",\n",
    "    \"description\": \"Get the current weather in a given location\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"location\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The city and state, e.g. San Francisco, CA\",\n",
    "            },\n",
    "        },\n",
    "        \"required\": [\"location\"],\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "toolPrompt = f\"\"\"\n",
    "You have access to the following functions:\n",
    "\n",
    "Use the function '{weatherTool[\"name\"]}' to '{weatherTool[\"description\"]}':\n",
    "{json.dumps(weatherTool)}\n",
    "\n",
    "If you choose to call a function ONLY reply in the following format with no prefix or suffix:\n",
    "\n",
    "<function=example_function_name>{{\\\"example_name\\\": \\\"example_value\\\"}}</function>\n",
    "\n",
    "Reminder:\n",
    "- Function calls MUST follow the specified format, start with <function= and end with </function>\n",
    "- Required parameters MUST be specified\n",
    "- Only call one function at a time\n",
    "- Put the entire function call reply on one line\n",
    "- If there is no function call available, answer the question like normal with your current knowledge and do not tell the user about function calls\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "  \t{\n",
    "        \"role\": \"system\",\n",
    "        \"content\": toolPrompt,\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"What is the weather in Tokyo?\",\n",
    "    },\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function=get_current_weather>{\"location\": \"Tokyo, Japan\"}</function>\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"llama3.1\",\n",
    "    messages=messages,\n",
    "    max_tokens=1024,\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "messages.append(response.choices[0].message)\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'function': 'get_current_weather', 'arguments': {'location': 'Tokyo, Japan'}}\n"
     ]
    }
   ],
   "source": [
    "def parse_tool_response(response: str):\n",
    "    function_regex = r\"<function=(\\w+)>(.*?)</function>\"\n",
    "    match = re.search(function_regex, response)\n",
    "\n",
    "    if match:\n",
    "        function_name, args_string = match.groups()\n",
    "        try:\n",
    "            args = json.loads(args_string)\n",
    "            return {\n",
    "                \"function\": function_name,\n",
    "                \"arguments\": args,\n",
    "            }\n",
    "        except json.JSONDecodeError as error:\n",
    "            print(f\"Error parsing function arguments: {error}\")\n",
    "            return None\n",
    "    return None\n",
    "\n",
    "parsed_response = parse_tool_response(response.choices[0].message.content)\n",
    "print(parse_tool_response(response.choices[0].message.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weather answer is:  62 degrees and cloudy\n",
      "Answer from the LLM:  ChatCompletionMessage(content='<function=get_current_weather>{\"location\": \"Tokyo, Japan\"}</function>', refusal=None, role='assistant', function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "def get_current_weather(location: str) -> str:\n",
    "    # This would be replaced by a weather API\n",
    "    if location == \"Tokyo, Japan\":\n",
    "        return \"62 degrees and cloudy\"\n",
    "    elif location == \"Philadelphia, PA\":\n",
    "        return \"83 degrees and sunny\"\n",
    "    return \"Weather is unknown\"\n",
    "\n",
    "if parsed_response:\n",
    "    available_functions = {\"get_current_weather\": get_current_weather}\n",
    "    function_to_call = available_functions[parsed_response[\"function\"]]\n",
    "    weather = function_to_call(parsed_response[\"arguments\"][\"location\"])\n",
    "    messages.append(\n",
    "        {\n",
    "            \"role\": \"tool\",\n",
    "            \"content\": weather,\n",
    "        }\n",
    "    )\n",
    "    print(\"Weather answer is: \", weather)\n",
    "\n",
    "    res = client.chat.completions.create(\n",
    "        model=\"llama3.1\",\n",
    "        messages=messages,\n",
    "        max_tokens=1000,\n",
    "        temperature=0,\n",
    "    )\n",
    "    print(\"Answer from the LLM: \", res.choices[0].message)\n",
    "else:\n",
    "    print(\"No function call found in the response\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
